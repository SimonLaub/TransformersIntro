{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# This Notebook is based on a clone of\n",
        "# Joao Fernando Ferreira Goncalves\n",
        "# original notebook that can be found here:\n",
        "# https://github.com/Joaoffg/AISocIMP23/\n",
        "#\n",
        "# See original notebook here:\n",
        "# https://colab.research.google.com/drive/1ya-NLUyfbs0lZJu1pQIkhoA4POtTsVkv?usp=sharing\n",
        "#\n",
        "# Changes to the original notebook was made, according to\n",
        "# to talks with Joao, after Mads and I visited\n",
        "# Rotterdam Univerity in January 2024.\n",
        "#\n",
        "# March 4, 2024\n",
        "# sila"
      ],
      "metadata": {
        "id": "N3NzWvfjllx3"
      },
      "id": "N3NzWvfjllx3",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training a language model using Transformers\n",
        "\n",
        "Training a language model is a more advanced form of machine learning,\n",
        "therefore we need to install some libraries that are not default for Google Colab.\n",
        "We also clone our GitHub repository as usual."
      ],
      "metadata": {
        "id": "V_grb1E11Nk5"
      },
      "id": "V_grb1E11Nk5"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "!pip install transformers\n",
        "!pip install sentencepiece\n",
        "!pip install accelerate\n",
        "!git clone https://github.com/Joaoffg/AISocIMP23/"
      ],
      "metadata": {
        "id": "3jcgePv6iqDD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6995161-100c-4fd5-be0e-31e4936933e6"
      },
      "id": "3jcgePv6iqDD",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: dill, multiprocess, datasets\n",
            "Successfully installed datasets-2.18.0 dill-0.3.8 multiprocess-0.70.16\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.27.2-py3-none-any.whl (279 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.0/280.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.27.2\n",
            "Cloning into 'AISocIMP23'...\n",
            "remote: Enumerating objects: 284, done.\u001b[K\n",
            "remote: Counting objects: 100% (190/190), done.\u001b[K\n",
            "remote: Compressing objects: 100% (168/168), done.\u001b[K\n",
            "remote: Total 284 (delta 57), reused 72 (delta 15), pack-reused 94\u001b[K\n",
            "Receiving objects: 100% (284/284), 109.91 MiB | 13.06 MiB/s, done.\n",
            "Resolving deltas: 100% (78/78), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After installing the libraries, we need to import them so we can use them in out code."
      ],
      "metadata": {
        "id": "9CkKgAaJAJ12"
      },
      "id": "9CkKgAaJAJ12"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "b3467bc6-9d41-4f89-b82c-23bfb82b603e",
      "metadata": {
        "id": "b3467bc6-9d41-4f89-b82c-23bfb82b603e"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "import re\n",
        "import os\n",
        "import torch\n",
        "from transformers import LlamaTokenizer, LlamaConfig, LlamaModel, LlamaForCausalLM, Trainer, TrainingArguments"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now you must add your own documents to the folder Texts.\n",
        "# Here I have added a text about Proshop"
      ],
      "metadata": {
        "id": "4OAvTM34Ehbo"
      },
      "id": "4OAvTM34Ehbo",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%ls \"/content/AISocIMP23/Week 4/Texts\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qskQTOpn3uf",
        "outputId": "b485152b-a7d9-41d3-8e5c-47b2b9664de1"
      },
      "id": "5qskQTOpn3uf",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Proshop.txt  'ThesisDraft_MariaPalaciosBarea_622509 (1).txt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This part loads all of the text data that you will use to train the language model."
      ],
      "metadata": {
        "id": "wzxNoqk-AP8F"
      },
      "id": "wzxNoqk-AP8F"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "aa705ed2-e705-411e-98bb-bc96317e3a2d",
      "metadata": {
        "id": "aa705ed2-e705-411e-98bb-bc96317e3a2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "6ab3edcd93bf4a3dbb41b84016d63e9a",
            "42cd2a685495462690d832705f74bc38",
            "c388142a3d174e95a0903c737d7d5d35",
            "a3043948cfec47a19beee3b1d115f7d5",
            "c86eb487b4284295842c5b0a4cde2ee2",
            "5070af7574064badb7009629e918e162",
            "263d36d19d53466baf1cc30afd72e129",
            "a1f928cd5e794744a3ff0877b08bd47d",
            "ce78e92e487a4a67b67eadef7b5a7942",
            "9c46a55a1a7446a8be0837a4a800dd41",
            "2398f72814f84d2487af5b104a92469e"
          ]
        },
        "outputId": "ba94a3ac-45fe-4e23-9601-8765f88861f4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6ab3edcd93bf4a3dbb41b84016d63e9a"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "dataset = load_dataset(\"text\",\n",
        "                       data_dir=\"/content/AISocIMP23/Week 4/Texts\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# What you must do:\n",
        "# 1. Try to run the complete notebook based om this text.\n",
        "# 2. Then re-run notebook, but now with more texts added, and see what\n",
        "#     happens as information from these new texts books are queried.\n",
        "#\n",
        "# Now we should be ready to the second part."
      ],
      "metadata": {
        "id": "dCAG0F8VqKdD"
      },
      "id": "dCAG0F8VqKdD",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This part tokenizes the dataset, which means that it converts all of the words into numbers that can be processed by the neural network."
      ],
      "metadata": {
        "id": "ruXFeO68Ab-V"
      },
      "id": "ruXFeO68Ab-V"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "9ef7e878-1b11-4019-b4b2-9217e6d554a6",
      "metadata": {
        "id": "9ef7e878-1b11-4019-b4b2-9217e6d554a6"
      },
      "outputs": [],
      "source": [
        "tokenizer = LlamaTokenizer.from_pretrained('/content/AISocIMP23/Week 4/Token')\n",
        "\n",
        "def chunk_examples(examples,chunk_lenght=128, min_chunk_lenght = 25):\n",
        "    chunks = []\n",
        "    for text in examples[\"text\"]:\n",
        "        tokenized = tokenizer(text,add_special_tokens=False)\n",
        "        if len(tokenized.input_ids) > min_chunk_lenght:\n",
        "            input_ids = [tokenizer.bos_token_id] + tokenized.input_ids + [tokenizer.eos_token_id]\n",
        "            attention_mask = [1] + tokenized.attention_mask + [1]\n",
        "            for i in range(0, len(tokenized.input_ids), chunk_lenght):\n",
        "                cunk_input_ids = input_ids[i:i + chunk_lenght]\n",
        "                cunk_att_mask = attention_mask[i:i + chunk_lenght]\n",
        "                cur_chunk_len = len(cunk_input_ids)\n",
        "\n",
        "                if  cur_chunk_len < chunk_lenght:\n",
        "                    cunk_input_ids = cunk_input_ids + [tokenizer.eos_token_id]*(chunk_lenght - cur_chunk_len)\n",
        "                    cunk_att_mask = cunk_att_mask + [0]*(chunk_lenght - cur_chunk_len)\n",
        "\n",
        "                chunks += [{\"input_ids\":torch.tensor(cunk_input_ids),\n",
        "                        \"attention_mask\": torch.tensor(cunk_att_mask),\n",
        "                        \"labels\": torch.tensor(cunk_input_ids)}\n",
        "                        #\"raw\":tokenizer.decode(cunk_input_ids)}\n",
        "\n",
        "                        ]\n",
        "\n",
        "\n",
        "    return {\"chunks\": chunks}\n",
        "\n",
        "\n",
        "chunked_dataset = dataset.map(chunk_examples, batched=True, remove_columns=['text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we define our model architecture, we are using a LlaMa based model for this exercise. You can change the complexity factor below to make the model more simple or more complex."
      ],
      "metadata": {
        "id": "o-nI9L8rAppV"
      },
      "id": "o-nI9L8rAppV"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "a17a48d0-2377-4b62-92db-bd859847cb8d",
      "metadata": {
        "id": "a17a48d0-2377-4b62-92db-bd859847cb8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a04f69b3-8bc4-43f5-cd4c-45477107dab6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LlaMa Model Size: 162.0M parameters\n"
          ]
        }
      ],
      "source": [
        "complexity_reduction=2\n",
        "\n",
        "config = LlamaConfig(\n",
        "    vocab_size = 32000,\n",
        "    hidden_size= int(2048/complexity_reduction),\n",
        "    intermediate_size = int(5120/complexity_reduction),\n",
        "    num_hidden_layers = int(16/complexity_reduction),\n",
        "    num_attention_heads = int(16/complexity_reduction),\n",
        "    max_position_embeddings = 2048 ,\n",
        "    rms_norm_eps = 1e-12\n",
        ")\n",
        "\n",
        "model = LlamaForCausalLM(config)\n",
        "model_size = sum(t.numel() for t in model.parameters())\n",
        "print(f\"LlaMa Model Size: {model_size/1000**2:.1f}M parameters\")\n",
        "\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here you define the training arguments. You can ignore most of them, they are default values, but you may want to tweak the batch_sizes and the learning rate."
      ],
      "metadata": {
        "id": "SKqz5tSxA-0M"
      },
      "id": "SKqz5tSxA-0M"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "67f739a3-8b16-407e-8439-2f22c40bf991",
      "metadata": {
        "id": "67f739a3-8b16-407e-8439-2f22c40bf991"
      },
      "outputs": [],
      "source": [
        "args = TrainingArguments(\n",
        "    output_dir=\"erasmian-lm/medium\",\n",
        "    per_device_train_batch_size=1,\n",
        "    per_device_eval_batch_size=1,\n",
        "    evaluation_strategy=\"no\",\n",
        "    eval_steps=5_000,\n",
        "    logging_steps=5_000,\n",
        "    num_train_epochs=5,\n",
        "    weight_decay=0.1,\n",
        "    warmup_steps=1_000,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    learning_rate=0.0001,\n",
        "    save_steps=5_000,\n",
        "    fp16=True,\n",
        "    save_strategy = \"epoch\", #save only latest model at end of epoch instead of 5k steps.\n",
        "    save_total_limit = 1 # save only latest 3 epochs\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: Try num_train_epochs=5, for improved performance."
      ],
      "metadata": {
        "id": "U1dlMZNcqoKF"
      },
      "id": "U1dlMZNcqoKF",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This step trains the model, exciting!"
      ],
      "metadata": {
        "id": "aorFhYglBfJU"
      },
      "id": "aorFhYglBfJU"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "1f62d16f-51c6-4d52-8c97-79198d877178",
      "metadata": {
        "id": "1f62d16f-51c6-4d52-8c97-79198d877178",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "bb818100-dde2-4dcc-f462-760a49424574"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2970' max='2970' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2970/2970 11:30, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2970, training_loss=3.0138303609006734, metrics={'train_runtime': 692.3717, 'train_samples_per_second': 4.29, 'train_steps_per_second': 4.29, 'total_flos': 294824116224000.0, 'train_loss': 3.0138303609006734, 'epoch': 5.0})"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    args=args,\n",
        "    train_dataset=chunked_dataset['train']['chunks']\n",
        "\n",
        ")\n",
        "\n",
        "model = torch.compile(model)\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And here you can test how the model is actually performing by generating some text. You can write the start of the text between \"\" in the input_text field."
      ],
      "metadata": {
        "id": "ABVa4YUcBkcD"
      },
      "id": "ABVa4YUcBkcD"
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "ef0d26df-a476-4631-b08f-7c123c27fb4a",
      "metadata": {
        "id": "ef0d26df-a476-4631-b08f-7c123c27fb4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1748760-3138-441f-c2f8-1cbc64953acb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Proshop is anshop a system’s sells products, the Netherlandsing between strength and household in the warehouse. This can be largely products as being more than other, but it is in the same, not require things than being considered a man.']\n"
          ]
        }
      ],
      "source": [
        "from transformers import GenerationConfig\n",
        "\n",
        "input_text= \"Proshop is\"\n",
        "\n",
        "generation_config = GenerationConfig(\n",
        "    temperature=1,\n",
        "    top_p=0.95, #0.95\n",
        "    top_k=50,#50\n",
        "    repetition_penalty=1,\n",
        "    do_sample=True,\n",
        "    num_return_sequences=1\n",
        ")\n",
        "\n",
        "inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
        "inputs = inputs.to(\"cuda:0\")\n",
        "model = model.to(\"cuda:0\")\n",
        "outputs = model.generate(**inputs, num_beams=1, do_sample=True, max_length=128)\n",
        "print(tokenizer.batch_decode(outputs, skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now try to change the various settings, parameters.\n",
        "#\n",
        "# E.g.\n",
        "# Asking what 'Proshop is' now gives a somewhat better answer:\n",
        "# ['Proshop is a/s sells products in eight countries: Denmark, Norway, Austria, Austria, where not be not by it.']\n",
        "# 'Proshop a/s sells products' gives:\n",
        "# ['Proshop a/s sells products in eight countries: Denmark, Norway, Austria, the results in a degree of skill and gender.']\n",
        "# Changing temperature to 0.1, top_p = 0.99, top_k = 10\n",
        "# makes the answer less imaginative, and is gives:\n",
        "#['Proshop a/s sells products in eight countries: Denmark, Finland, Sweden, Poland, co and Germany. The company.']\n",
        "# Raising the temperature to 10 gives:\n",
        "# ['Proshop a/s sells products in higher countries: Denmark: Denmark, Finland, the person, Finland, aiming to find women who are “ay, co.']\n",
        "# Changing temperature to 1, top_p = 0.99, top_k = 1 gives:\n",
        "# I.e. By specifying a Top K of 50, we’re saying, -Only look at the best 50 tokens-\n",
        "# Top K lets us limit how many options we consider while sampling.\n",
        "# Top P says, - Only consider the possibilities that equal or exceed this value.- It gives:\n",
        "# ['Proshop a/s sells products in eight countries: Denmark, Norway, though, Austria, Austria, the Netherlands and Germany.']\n",
        "\n",
        "# With - Proshop is an online -\n",
        "# temperature 0.1, top_p = 0.99, top_k = 1\n",
        "# it gives: ['Proshop is an online shop that sellsells Aar ']\n",
        "# Well, at least shop looked ok.\n",
        "#\n",
        "# Resetting to 'Proshop is\"\n",
        "# temperature 1, top_p = 0.95, top_k = 50\n",
        "# we get:\n",
        "# ['Proshop is anshop a system’s sells products, the Netherlandsing between strength and household in the warehouse.']\n",
        "# At least there is something about shop, sell products and warehouse in it !"
      ],
      "metadata": {
        "id": "hPqf1QGQBcz5"
      },
      "id": "hPqf1QGQBcz5",
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding"
      ],
      "metadata": {
        "id": "iWHUIYwHP6bj"
      },
      "id": "iWHUIYwHP6bj",
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIE-fdyxQarl",
        "outputId": "a9b5ee87-d77e-4e74-ae01-a6d15d1217ce"
      },
      "id": "gIE-fdyxQarl",
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Mar  4 16:17:52 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   74C    P0              33W /  70W |   3555MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6ab3edcd93bf4a3dbb41b84016d63e9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_42cd2a685495462690d832705f74bc38",
              "IPY_MODEL_c388142a3d174e95a0903c737d7d5d35",
              "IPY_MODEL_a3043948cfec47a19beee3b1d115f7d5"
            ],
            "layout": "IPY_MODEL_c86eb487b4284295842c5b0a4cde2ee2"
          }
        },
        "42cd2a685495462690d832705f74bc38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5070af7574064badb7009629e918e162",
            "placeholder": "​",
            "style": "IPY_MODEL_263d36d19d53466baf1cc30afd72e129",
            "value": "Generating train split: "
          }
        },
        "c388142a3d174e95a0903c737d7d5d35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1f928cd5e794744a3ff0877b08bd47d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ce78e92e487a4a67b67eadef7b5a7942",
            "value": 1
          }
        },
        "a3043948cfec47a19beee3b1d115f7d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c46a55a1a7446a8be0837a4a800dd41",
            "placeholder": "​",
            "style": "IPY_MODEL_2398f72814f84d2487af5b104a92469e",
            "value": " 1639/0 [00:00&lt;00:00, 30809.92 examples/s]"
          }
        },
        "c86eb487b4284295842c5b0a4cde2ee2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5070af7574064badb7009629e918e162": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "263d36d19d53466baf1cc30afd72e129": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a1f928cd5e794744a3ff0877b08bd47d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "ce78e92e487a4a67b67eadef7b5a7942": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9c46a55a1a7446a8be0837a4a800dd41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2398f72814f84d2487af5b104a92469e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}