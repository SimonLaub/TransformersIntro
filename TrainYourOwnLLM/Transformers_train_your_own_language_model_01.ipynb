{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# This Notebook is based on a clone of\n",
        "# Joao Fernando Ferreira Goncalves\n",
        "# original notebook that can be found here:\n",
        "# https://github.com/Joaoffg/AISocIMP23/\n",
        "#\n",
        "# See original notebook here:\n",
        "# https://colab.research.google.com/drive/1ya-NLUyfbs0lZJu1pQIkhoA4POtTsVkv?usp=sharing\n",
        "#\n",
        "# Changes to the original notebook was made, according to\n",
        "# to talks with Joao, after Mads and I visited\n",
        "# Rotterdam Univerity in January 2024.\n",
        "#\n",
        "# February 26, 2024\n",
        "# sila"
      ],
      "metadata": {
        "id": "N3NzWvfjllx3"
      },
      "id": "N3NzWvfjllx3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training a language model using Transformers\n",
        "\n",
        "Training a language model is a more advanced form of machine learning,\n",
        "therefore we need to install some libraries that are not default for Google Colab.\n",
        "We also clone our GitHub repository as usual."
      ],
      "metadata": {
        "id": "V_grb1E11Nk5"
      },
      "id": "V_grb1E11Nk5"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "!pip install transformers\n",
        "!pip install sentencepiece\n",
        "!pip install accelerate\n",
        "!git clone https://github.com/Joaoffg/AISocIMP23/"
      ],
      "metadata": {
        "id": "3jcgePv6iqDD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1e1051c-892c-4e73-dfc8-f096f3a128d8"
      },
      "id": "3jcgePv6iqDD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: dill, multiprocess, datasets\n",
            "Successfully installed datasets-2.18.0 dill-0.3.8 multiprocess-0.70.16\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.27.2-py3-none-any.whl (279 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.0/280.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.27.2\n",
            "Cloning into 'AISocIMP23'...\n",
            "remote: Enumerating objects: 284, done.\u001b[K\n",
            "remote: Counting objects: 100% (190/190), done.\u001b[K\n",
            "remote: Compressing objects: 100% (168/168), done.\u001b[K\n",
            "remote: Total 284 (delta 57), reused 72 (delta 15), pack-reused 94\u001b[K\n",
            "Receiving objects: 100% (284/284), 109.91 MiB | 22.27 MiB/s, done.\n",
            "Resolving deltas: 100% (78/78), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After installing the libraries, we need to import them so we can use them in out code."
      ],
      "metadata": {
        "id": "9CkKgAaJAJ12"
      },
      "id": "9CkKgAaJAJ12"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3467bc6-9d41-4f89-b82c-23bfb82b603e",
      "metadata": {
        "id": "b3467bc6-9d41-4f89-b82c-23bfb82b603e"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "import re\n",
        "import os\n",
        "import torch\n",
        "from transformers import LlamaTokenizer, LlamaConfig, LlamaModel, LlamaForCausalLM, Trainer, TrainingArguments"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls \"/content/AISocIMP23/Week 4/Texts\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qskQTOpn3uf",
        "outputId": "d9be6bf8-5b21-4cc1-cbf1-72b2c26355d6"
      },
      "id": "5qskQTOpn3uf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'ThesisDraft_MariaPalaciosBarea_622509 (1).txt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This part loads all of the text data that you will use to train the language model."
      ],
      "metadata": {
        "id": "wzxNoqk-AP8F"
      },
      "id": "wzxNoqk-AP8F"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa705ed2-e705-411e-98bb-bc96317e3a2d",
      "metadata": {
        "id": "aa705ed2-e705-411e-98bb-bc96317e3a2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "9a959c989c974dcaa4cde26a8c2df063",
            "ad4b28553de647edb419ed09eb0631e6",
            "74308bfe29e54e8a8d67beb91c99adcd",
            "5ab095e502d44c3c8f86f2187194f2fb",
            "8119d357abfa4984ae30ac628e86030c",
            "f48f4c329b484262958751c785ef12af",
            "607a7d26afd540f4b3e1a070e1cb02a9",
            "2fc274177a0144cbadfb586f1fb01cb3",
            "bcdfb10c768f400ba19099d15cd7ab59",
            "98a157e5982f4df694e83e4b22260c55",
            "4dbcf24ae5be461abecc919ac3b4c88b"
          ]
        },
        "outputId": "60a727f6-3e0e-4e3f-8f70-ef4f89989e06"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9a959c989c974dcaa4cde26a8c2df063"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "dataset = load_dataset(\"text\",\n",
        "                       data_dir=\"/content/AISocIMP23/Week 4/Texts\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# What you must do:\n",
        "# 1. Try to run the complete notebook based om this text.\n",
        "# 2. Then re-run notebook, but now with more texts added, and see what\n",
        "#     happens as information from these new texts books are queried."
      ],
      "metadata": {
        "id": "dCAG0F8VqKdD"
      },
      "id": "dCAG0F8VqKdD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This part tokenizes the dataset, which means that it converts all of the words into numbers that can be processed by the neural network."
      ],
      "metadata": {
        "id": "ruXFeO68Ab-V"
      },
      "id": "ruXFeO68Ab-V"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ef7e878-1b11-4019-b4b2-9217e6d554a6",
      "metadata": {
        "id": "9ef7e878-1b11-4019-b4b2-9217e6d554a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "8b8207b1122049e2bd8a9e175bf91f58",
            "a1d1cd1a3d234bb093b4a6cbebbc195d",
            "0d9ef226b3db4134a23b41876515c28f",
            "9abfa51545804d2ca43e3488d3733358",
            "e13ba747be1c477f80ede686dd8acdf4",
            "45403296b1134496ba70a655d5508606",
            "13b58e3534c144f0856aa341780b563a",
            "2842cf0821fc427cb1f985e5abe4603f",
            "8279e90e6e0643799e731452e662d503",
            "786edc0f586746e8822d6de19d2e00e5",
            "0a50b579ef7c4969aca3b933a0ef9dbe"
          ]
        },
        "outputId": "25c7e87d-3218-4d7f-dd91-4a98a2c848f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1548 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8b8207b1122049e2bd8a9e175bf91f58"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "tokenizer = LlamaTokenizer.from_pretrained('/content/AISocIMP23/Week 4/Token')\n",
        "\n",
        "def chunk_examples(examples,chunk_lenght=128, min_chunk_lenght = 25):\n",
        "    chunks = []\n",
        "    for text in examples[\"text\"]:\n",
        "        tokenized = tokenizer(text,add_special_tokens=False)\n",
        "        if len(tokenized.input_ids) > min_chunk_lenght:\n",
        "            input_ids = [tokenizer.bos_token_id] + tokenized.input_ids + [tokenizer.eos_token_id]\n",
        "            attention_mask = [1] + tokenized.attention_mask + [1]\n",
        "            for i in range(0, len(tokenized.input_ids), chunk_lenght):\n",
        "                cunk_input_ids = input_ids[i:i + chunk_lenght]\n",
        "                cunk_att_mask = attention_mask[i:i + chunk_lenght]\n",
        "                cur_chunk_len = len(cunk_input_ids)\n",
        "\n",
        "                if  cur_chunk_len < chunk_lenght:\n",
        "                    cunk_input_ids = cunk_input_ids + [tokenizer.eos_token_id]*(chunk_lenght - cur_chunk_len)\n",
        "                    cunk_att_mask = cunk_att_mask + [0]*(chunk_lenght - cur_chunk_len)\n",
        "\n",
        "                chunks += [{\"input_ids\":torch.tensor(cunk_input_ids),\n",
        "                        \"attention_mask\": torch.tensor(cunk_att_mask),\n",
        "                        \"labels\": torch.tensor(cunk_input_ids)}\n",
        "                        #\"raw\":tokenizer.decode(cunk_input_ids)}\n",
        "\n",
        "                        ]\n",
        "\n",
        "\n",
        "    return {\"chunks\": chunks}\n",
        "\n",
        "\n",
        "chunked_dataset = dataset.map(chunk_examples, batched=True, remove_columns=['text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we define our model architecture, we are using a LlaMa based model for this exercise. You can change the complexity factor below to make the model more simple or more complex."
      ],
      "metadata": {
        "id": "o-nI9L8rAppV"
      },
      "id": "o-nI9L8rAppV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a17a48d0-2377-4b62-92db-bd859847cb8d",
      "metadata": {
        "id": "a17a48d0-2377-4b62-92db-bd859847cb8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "253b167b-a20d-4dc5-868e-da865afdfdbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LlaMa Model Size: 162.0M parameters\n"
          ]
        }
      ],
      "source": [
        "complexity_reduction=2\n",
        "\n",
        "config = LlamaConfig(\n",
        "    vocab_size = 32000,\n",
        "    hidden_size= int(2048/complexity_reduction),\n",
        "    intermediate_size = int(5120/complexity_reduction),\n",
        "    num_hidden_layers = int(16/complexity_reduction),\n",
        "    num_attention_heads = int(16/complexity_reduction),\n",
        "    max_position_embeddings = 2048 ,\n",
        "    rms_norm_eps = 1e-12\n",
        ")\n",
        "\n",
        "model = LlamaForCausalLM(config)\n",
        "model_size = sum(t.numel() for t in model.parameters())\n",
        "print(f\"LlaMa Model Size: {model_size/1000**2:.1f}M parameters\")\n",
        "\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here you define the training arguments. You can ignore most of them, they are default values, but you may want to tweak the batch_sizes and the learning rate."
      ],
      "metadata": {
        "id": "SKqz5tSxA-0M"
      },
      "id": "SKqz5tSxA-0M"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67f739a3-8b16-407e-8439-2f22c40bf991",
      "metadata": {
        "id": "67f739a3-8b16-407e-8439-2f22c40bf991"
      },
      "outputs": [],
      "source": [
        "args = TrainingArguments(\n",
        "    output_dir=\"erasmian-lm/medium\",\n",
        "    per_device_train_batch_size=1,\n",
        "    per_device_eval_batch_size=1,\n",
        "    evaluation_strategy=\"no\",\n",
        "    eval_steps=5_000,\n",
        "    logging_steps=5_000,\n",
        "    num_train_epochs=1,\n",
        "    weight_decay=0.1,\n",
        "    warmup_steps=1_000,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    learning_rate=0.0001,\n",
        "    save_steps=5_000,\n",
        "    fp16=True,\n",
        "    save_strategy = \"epoch\", #save only latest model at end of epoch instead of 5k steps.\n",
        "    save_total_limit = 1 # save only latest 3 epochs\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: Try num_train_epochs=5, for improved performance."
      ],
      "metadata": {
        "id": "U1dlMZNcqoKF"
      },
      "id": "U1dlMZNcqoKF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This step trains the model, exciting!"
      ],
      "metadata": {
        "id": "aorFhYglBfJU"
      },
      "id": "aorFhYglBfJU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f62d16f-51c6-4d52-8c97-79198d877178",
      "metadata": {
        "id": "1f62d16f-51c6-4d52-8c97-79198d877178",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "2ccc9902-ab61-47d8-f933-174ba28f7451"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='560' max='560' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [560/560 02:05, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=560, training_loss=5.395074898856027, metrics={'train_runtime': 127.3823, 'train_samples_per_second': 4.396, 'train_steps_per_second': 4.396, 'total_flos': 55589732352000.0, 'train_loss': 5.395074898856027, 'epoch': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    args=args,\n",
        "    train_dataset=chunked_dataset['train']['chunks']\n",
        "\n",
        ")\n",
        "\n",
        "model = torch.compile(model)\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And here you can test how the model is actually performing by generating some text. You can write the start of the text between \"\" in the input_text field."
      ],
      "metadata": {
        "id": "ABVa4YUcBkcD"
      },
      "id": "ABVa4YUcBkcD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef0d26df-a476-4631-b08f-7c123c27fb4a",
      "metadata": {
        "id": "ef0d26df-a476-4631-b08f-7c123c27fb4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63d2dee0-85e0-4f5c-9a92-c91a364a48cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Erasmus University is and the of the of to colour, be the with the the prompt the “ resulting”.” as the a. The to the the its the are findings this, as a ( in the resulting this or was. The of the this additionally the “ findings biases which that on its from the additionally women biases a this the”, the which are on by the survey prompt a of the a this research to the the in the as the its andions, and the on resulting “’s this human that the they. This by the from biases women complet and “ to the the additionally complet. In in complet are']\n"
          ]
        }
      ],
      "source": [
        "from transformers import GenerationConfig\n",
        "\n",
        "input_text= \"Erasmus University is\"\n",
        "\n",
        "generation_config = GenerationConfig(\n",
        "    temperature=1,\n",
        "    top_p=0.95,\n",
        "    top_k=50,\n",
        "    repetition_penalty=1,\n",
        "    do_sample=True,\n",
        "    num_return_sequences=1\n",
        ")\n",
        "\n",
        "inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
        "inputs = inputs.to(\"cuda:0\")\n",
        "model = model.to(\"cuda:0\")\n",
        "outputs = model.generate(**inputs, num_beams=1, do_sample=True, max_length=128)\n",
        "print(tokenizer.batch_decode(outputs, skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Asking what Proshop is gives a nonsense answer\n",
        "# 'Proshop is by, biases’s biases feel, and the women by a in the ( complet it from the the, as the social in theing that these of the other. For the to the are of the its in this and the in the which social” of the this ( additionally the the “ ( social its it is of the’s that GPT-3 ( these prompt that “ are the ( as the a ( was of the the (, theed the was “ of more this “ an to the socialed complet are a the social.']\n"
      ],
      "metadata": {
        "id": "hPqf1QGQBcz5"
      },
      "id": "hPqf1QGQBcz5",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9a959c989c974dcaa4cde26a8c2df063": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ad4b28553de647edb419ed09eb0631e6",
              "IPY_MODEL_74308bfe29e54e8a8d67beb91c99adcd",
              "IPY_MODEL_5ab095e502d44c3c8f86f2187194f2fb"
            ],
            "layout": "IPY_MODEL_8119d357abfa4984ae30ac628e86030c"
          }
        },
        "ad4b28553de647edb419ed09eb0631e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f48f4c329b484262958751c785ef12af",
            "placeholder": "​",
            "style": "IPY_MODEL_607a7d26afd540f4b3e1a070e1cb02a9",
            "value": "Generating train split: "
          }
        },
        "74308bfe29e54e8a8d67beb91c99adcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fc274177a0144cbadfb586f1fb01cb3",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bcdfb10c768f400ba19099d15cd7ab59",
            "value": 1
          }
        },
        "5ab095e502d44c3c8f86f2187194f2fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98a157e5982f4df694e83e4b22260c55",
            "placeholder": "​",
            "style": "IPY_MODEL_4dbcf24ae5be461abecc919ac3b4c88b",
            "value": " 1548/0 [00:00&lt;00:00, 27418.73 examples/s]"
          }
        },
        "8119d357abfa4984ae30ac628e86030c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f48f4c329b484262958751c785ef12af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "607a7d26afd540f4b3e1a070e1cb02a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2fc274177a0144cbadfb586f1fb01cb3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "bcdfb10c768f400ba19099d15cd7ab59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "98a157e5982f4df694e83e4b22260c55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4dbcf24ae5be461abecc919ac3b4c88b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b8207b1122049e2bd8a9e175bf91f58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a1d1cd1a3d234bb093b4a6cbebbc195d",
              "IPY_MODEL_0d9ef226b3db4134a23b41876515c28f",
              "IPY_MODEL_9abfa51545804d2ca43e3488d3733358"
            ],
            "layout": "IPY_MODEL_e13ba747be1c477f80ede686dd8acdf4"
          }
        },
        "a1d1cd1a3d234bb093b4a6cbebbc195d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45403296b1134496ba70a655d5508606",
            "placeholder": "​",
            "style": "IPY_MODEL_13b58e3534c144f0856aa341780b563a",
            "value": "Map: 100%"
          }
        },
        "0d9ef226b3db4134a23b41876515c28f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2842cf0821fc427cb1f985e5abe4603f",
            "max": 1548,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8279e90e6e0643799e731452e662d503",
            "value": 1548
          }
        },
        "9abfa51545804d2ca43e3488d3733358": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_786edc0f586746e8822d6de19d2e00e5",
            "placeholder": "​",
            "style": "IPY_MODEL_0a50b579ef7c4969aca3b933a0ef9dbe",
            "value": " 1548/1548 [00:02&lt;00:00, 702.75 examples/s]"
          }
        },
        "e13ba747be1c477f80ede686dd8acdf4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45403296b1134496ba70a655d5508606": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13b58e3534c144f0856aa341780b563a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2842cf0821fc427cb1f985e5abe4603f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8279e90e6e0643799e731452e662d503": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "786edc0f586746e8822d6de19d2e00e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a50b579ef7c4969aca3b933a0ef9dbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}